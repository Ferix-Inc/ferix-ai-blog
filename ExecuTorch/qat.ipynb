{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExecuTorchを用いたQuantization Aware Training実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import time\n",
    "import warnings\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch._export import capture_pre_autograd_graph\n",
    "from torch.export import export, ExportedProgram\n",
    "from torch.ao.quantization import move_exported_model_to_eval\n",
    "from torch.ao.quantization.quantize_pt2e import prepare_qat_pt2e, convert_pt2e\n",
    "from torch.ao.quantization.quantizer.xnnpack_quantizer import XNNPACKQuantizer, get_symmetric_quantization_config\n",
    "from executorch.exir import EdgeCompileConfig, to_edge\n",
    "from executorch.backends.xnnpack.partition.xnnpack_partitioner import XnnpackPartitioner\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import timm\n",
    "\n",
    "from utils import AverageMeter, seed_everything\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "logging.getLogger('torch._export').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)\n",
    "DATA_DIR = Path(os.path.expanduser(\"~\")) / \"Data\"\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "train_dataset = MNIST(root=DATA_DIR, train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST(root=DATA_DIR, train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('resnet18d', pretrained=True, in_chans=1, num_classes=10).to(device)\n",
    "example_inputs = (torch.randn(2, 1, 28, 28).to(device),)\n",
    "dynamic_shapes = {\n",
    "    \"x\": {0: torch.export.Dim(\"batch\", min=2, max=1024)},\n",
    "}\n",
    "pre_aten_model = capture_pre_autograd_graph(\n",
    "    model,\n",
    "    example_inputs,\n",
    "    dynamic_shapes=dynamic_shapes,\n",
    ")\n",
    "quantizer = XNNPACKQuantizer()\n",
    "quantizer.set_global(get_symmetric_quantization_config(is_qat=True))\n",
    "prepared_model = prepare_qat_pt2e(pre_aten_model, quantizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"\n",
    "    Computes the accuracy over the k top predictions for the specified\n",
    "    values of k.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "\n",
    "def evaluate(model, criterion, data_loader, device):\n",
    "    if isinstance(model, ExportedProgram):\n",
    "        move_exported_model_to_eval(model)\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    with torch.no_grad():\n",
    "        for image, target in data_loader:\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(image)\n",
    "            loss = criterion(output, target)\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            top1.update(acc1[0], image.size(0))\n",
    "            top5.update(acc5[0], image.size(0))\n",
    "\n",
    "    return top1, top5\n",
    "\n",
    "\n",
    "def train_one_epoch(model, criterion, optimizer, data_loader, device):\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    avgloss = AverageMeter('Loss', '1.5f')\n",
    "    for image, target in data_loader:\n",
    "        start_time = time.time()\n",
    "        image, target = image.to(device), target.to(device)\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        top1.update(acc1[0], image.size(0))\n",
    "        top5.update(acc5[0], image.size(0))\n",
    "        avgloss.update(loss, image.size(0))\n",
    "\n",
    "    print(f'train set:  * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set:  * Acc@1 38.772 Acc@5 76.488\n",
      "Epoch  1: Evaluation accuracy : 67.91\n",
      "train set:  * Acc@1 80.428 Acc@5 96.277\n",
      "Epoch  2: Evaluation accuracy : 89.21\n",
      "train set:  * Acc@1 91.373 Acc@5 98.880\n",
      "Epoch  3: Evaluation accuracy : 93.44\n",
      "train set:  * Acc@1 94.445 Acc@5 99.450\n",
      "Epoch  4: Evaluation accuracy : 95.01\n",
      "train set:  * Acc@1 95.778 Acc@5 99.642\n",
      "Epoch  5: Evaluation accuracy : 95.80\n",
      "train set:  * Acc@1 96.555 Acc@5 99.710\n",
      "Epoch  6: Evaluation accuracy : 96.35\n",
      "train set:  * Acc@1 97.043 Acc@5 99.788\n",
      "Epoch  7: Evaluation accuracy : 96.58\n",
      "train set:  * Acc@1 97.468 Acc@5 99.837\n",
      "Epoch  8: Evaluation accuracy : 97.04\n",
      "train set:  * Acc@1 97.817 Acc@5 99.907\n",
      "Epoch  9: Evaluation accuracy : 97.30\n",
      "train set:  * Acc@1 98.045 Acc@5 99.905\n",
      "Epoch 10: Evaluation accuracy : 97.41\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 10\n",
    "num_observer_update_epochs = 8\n",
    "num_batch_norm_update_epochs = 8\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(prepared_model.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    train_one_epoch(\n",
    "        model=prepared_model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_loader,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # Optionally disable observer/batchnorm stats after certain number of epochs\n",
    "    if epoch >= num_observer_update_epochs:\n",
    "        # Freeze quantizer parameters\n",
    "        prepared_model.apply(torch.ao.quantization.disable_observer)\n",
    "    if epoch >= num_batch_norm_update_epochs:\n",
    "        # Freeze batch norm mean and variance estimates\n",
    "        prepared_model.apply(torch.nn.intrinsic.qat.freeze_bn_stats)\n",
    "\n",
    "    prepared_model_copy = copy.deepcopy(prepared_model)\n",
    "    quantized_model = convert_pt2e(prepared_model_copy)\n",
    "    top1, _ = evaluate(quantized_model, criterion, test_loader, device)\n",
    "    print(f'Epoch {epoch+1:2d}: Evaluation accuracy : {top1.avg:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = convert_pt2e(prepared_model.to(torch.device(\"cpu\")))\n",
    "move_exported_model_to_eval(quantized_model)\n",
    "\n",
    "example_inputs = (torch.randn(1, 1, 28, 28).to(torch.device('cpu')),)\n",
    "core_aten_ep = export(quantized_model, example_inputs)\n",
    "edge_m = to_edge(\n",
    "    core_aten_ep,\n",
    "    compile_config=EdgeCompileConfig(_check_ir_validity=False),\n",
    ")\n",
    "\n",
    "edge_m = edge_m.to_backend(XnnpackPartitioner())\n",
    "exec_prog = edge_m.to_executorch()\n",
    "\n",
    "exec_prog_path = f'models/resnet18_qat_ep{n_epoch}.pte'\n",
    "with open(exec_prog_path, 'wb') as f:\n",
    "    f.write(exec_prog.buffer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
